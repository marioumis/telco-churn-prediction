import pandas as pd
import joblib
import os
# ============================
# 1. Charger les donn√©es
# ============================
# ‚ö† change le nom du fichier si besoin
df = pd.read_csv(r"../data/telco.csv")

print("Aper√ßu des donn√©es :")
print(df.head())
print("\nInfos g√©n√©rales :")
print(df.info())
print("\nValeurs possibles de Churn :")
print(df["Churn"].value_counts())


# ============================
# 2. Nettoyage minimum
# ============================
# √Ä quoi √ßa sert ?
# - 'TotalCharges' est parfois lue comme texte, on la convertit en nombre
# - les lignes o√π √ßa donne NaN sont supprim√©es

df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
df = df.dropna(subset=["TotalCharges"])

# 'customerID' ne sert pas pour pr√©dire, on l'enl√®ve
if "customerID" in df.columns:
    df = df.drop(columns=["customerID"])


# ============================
# 3. S√©parer features (X) et cible (y)
# ============================
# √Ä quoi √ßa sert ?
# - X = les colonnes qu'on utilise pour pr√©dire
# - y = ce qu'on veut pr√©dire (Churn : Oui/Non ‚Üí 1/0)

y = df["Churn"].map({"No": 0, "Yes": 1})  # 0 = reste, 1 = quitte
X = df.drop(columns=["Churn"])

print("\nDimensions de X et y :")
print("X :", X.shape)
print("y :", y.shape)


# ============================
# 4. Pr√©paration : colonnes num√©riques / cat√©gorielles
# ============================
# √Ä quoi √ßa sert ?
# - les mod√®les scikit-learn veulent du num√©rique
# - on va encoder les colonnes de type 'object' (cat√©gorielles)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier

cat_cols = X.select_dtypes(include=["object"]).columns
num_cols = X.select_dtypes(exclude=["object"]).columns

print("\nColonnes num√©riques :", list(num_cols))
print("Colonnes cat√©gorielles :", list(cat_cols))

preprocessor = ColumnTransformer(
    transformers=[
        ("num", "passthrough", num_cols),  # on laisse passer les colonnes num√©riques
        ("cat", OneHotEncoder(handle_unknown="ignore"), cat_cols),
    ]
)


# ============================
# 5. Train / Test split + mod√®le
# ============================
# √Ä quoi √ßa sert ?
# - on coupe les donn√©es en :
#     - train : pour entra√Æner le mod√®le
#     - test : pour √©valuer sur des donn√©es jamais vues

X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    stratify=y,          # garde la proportion de churn identique
    random_state=42
)

model = DecisionTreeClassifier(
    max_depth=5,
    random_state=42
)

clf = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("model", model),
])

# Entra√Ænement
clf.fit(X_train, y_train)
print("\n‚úÖ Mod√®le entra√Æn√©.")


# ============================
# 6. √âvaluation du mod√®le
# ============================
# √Ä quoi √ßa sert ?
# - voir si le mod√®le a un minimum de performance
# - accuracy + rapport de classification + matrice de confusion

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

y_pred = clf.predict(X_test)

print("\nAccuracy sur le test :", accuracy_score(y_test, y_pred))
print("\nClassification report :")
print(classification_report(y_test, y_pred))

print("\nMatrice de confusion :")
print(confusion_matrix(y_test, y_pred))


# ============================
# 7. Sauvegarder le mod√®le
# ============================
# On sauvegarde dans le m√™me dossier que train_model.py (src/)
BASE_DIR = os.path.dirname(__file__)           # dossier src
model_path = os.path.join(BASE_DIR, "model.joblib")

joblib.dump(clf, model_path)
print(f"üíæ Mod√®le sauvegard√© dans {model_path}")
